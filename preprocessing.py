<<<<<<< Updated upstream
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"preprocessing.py","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"hbVhpN62LOF_","colab_type":"code","outputId":"06a7b510-36e7-4e71-c35d-89c0ea9ec269","executionInfo":{"status":"ok","timestamp":1573919065760,"user_tz":-330,"elapsed":31322,"user":{"displayName":"Abhijeet Ghubade","photoUrl":"","userId":"11507905937059054371"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["import pandas as pd\n","import numpy as np\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv('fer2013.csv')\n","\n","width, height = 48, 48\n","\n","datapoints = data['pixels'].tolist()\n","\n","#getting features for training\n","X = []\n","for xseq in datapoints:\n","\n","    xx = [int(xp) for xp in xseq.split(' ')]\n","    xx = np.asarray(xx).reshape(width, height)\n","    X.append(xx.astype('float32'))\n","\n","X = np.asarray(X)\n","X = np.expand_dims(X, -1)\n","\n","#getting labels for training\n","y = pd.get_dummies(data['emotion']).as_matrix()\n","\n","#storing them using numpy\n","np.save('features', X)\n","np.save('labels', y)\n","\n","print(\"Preprocessing Done\")\n","print(\"Number of Features: \"+str(len(X[0])))\n","print(\"Number of Labels: \"+ str(len(y[0])))\n","print(\"Number of examples in dataset:\"+str(len(X)))\n","print(\"X,y stored in features.npy and labels.npy respectively\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Preprocessing Done\n","Number of Features: 48\n","Number of Labels: 7\n","Number of examples in dataset:35887\n","X,y stored in features.npy and labels.npy respectively\n"],"name":"stdout"}]}]}
=======
# -*- coding: utf-8 -*-
"""preprocessing.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PH6jn4SioqRK_UAkr6Ig6dCH-lBqkc9G
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")
data = pd.read_csv('fer2013.csv')

width, height = 48, 48

datapoints = data['pixels'].tolist()

#getting features for training
X = []
for xseq in datapoints:

    xx = [int(xp) for xp in xseq.split(' ')]
    xx = np.asarray(xx).reshape(width, height)
    X.append(xx.astype('float32'))

X = np.asarray(X)
X = np.expand_dims(X, -1)

#getting labels for training
y = pd.get_dummies(data['emotion']).as_matrix()

#storing them using numpy
np.save('features', X)
np.save('labels', y)

print("Preprocessing Done")
print("Number of Features: "+str(len(X[0])))
print("Number of Labels: "+ str(len(y[0])))
print("Number of examples in dataset:"+str(len(X)))
print("X,y stored in features.npy and labels.npy respectively")
>>>>>>> Stashed changes
